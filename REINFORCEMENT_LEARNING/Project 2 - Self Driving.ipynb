{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37cf1ed4-d771-4850-88e4-1b4153bcad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vihanga/Desktop/PYTHON_ENV/aiproenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b70aff-14f0-4f1d-ab29-10e975a08b94",
   "metadata": {},
   "source": [
    "# Test Enviornment #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cad15cc5-ea57-4838-8b9b-fc7be25ab8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enviornment_name = \"CarRacing-v0\"\n",
    "env = gym.make(enviornment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc2050-5164-4131-98ca-4cbb05a845f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad65e16f-049d-45e8-aed1-57bc529c9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e119b00d-7419-46ca-a9ff-3c67faf67f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1.  0.  0.], [1. 1. 1.], (3,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c55d4c1-d433-4026-86c1-7987960a02bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1294..1629 -> 335-tiles track\n",
      "Episodes:1 Score:-43.1137724550905\n",
      "Track generation: 1109..1390 -> 281-tiles track\n",
      "Episodes:2 Score:-28.571428571428864\n",
      "Track generation: 1113..1422 -> 309-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 974..1229 -> 255-tiles track\n",
      "Episodes:3 Score:-21.25984251968504\n",
      "Track generation: 1119..1403 -> 284-tiles track\n",
      "Episodes:4 Score:-32.86219081272129\n",
      "Track generation: 1197..1500 -> 303-tiles track\n",
      "Episodes:5 Score:-33.774834437086625\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range (1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done =False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(\"Episodes:{} Score:{}\".format(episode, score))\n",
    "env.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc414ad-7802-4c1b-953b-6455f2c688ce",
   "metadata": {},
   "source": [
    "# Train Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a7d92e2-9537-45ca-b661-23c46ec40564",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(enviornment_name)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50439f3e-90c8-4b9b-8571-2674e18bccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join(\"Training\", \"Logs\")\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55237334-69fe-4fcd-8f01-8bdeee5e5d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cae8db-fef2-4a52-9331-bcd24145acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e72d7-b55a-419b-adc7-93f4b3338c44",
   "metadata": {},
   "source": [
    "# Save model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c5d00d-bb21-49ba-a3c6-53e446afbc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join(\"Training\", \"Saved Models\",\"PPO_Driving_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de555ed-d6f7-401c-af94-5721009edc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(ppo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f73eb6-bf13-4812-96b5-ed372c13510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bfa659b-d4c2-4f35-832b-a3148ad49693",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(ppo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38715124-7f88-4be6-b27a-4717d0518092",
   "metadata": {},
   "source": [
    "# Evaluate and test #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc689b3-331f-45ac-9a4f-a341c48875dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vihanga/Desktop/PYTHON_ENV/aiproenv/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1084..1359 -> 275-tiles track\n",
      "Track generation: 1247..1563 -> 316-tiles track\n",
      "Track generation: 1027..1288 -> 261-tiles track\n",
      "Track generation: 1167..1463 -> 296-tiles track\n",
      "Track generation: 1159..1453 -> 294-tiles track\n",
      "Track generation: 959..1207 -> 248-tiles track\n",
      "Track generation: 1184..1484 -> 300-tiles track\n",
      "Track generation: 1128..1414 -> 286-tiles track\n",
      "Track generation: 1264..1584 -> 320-tiles track\n",
      "Track generation: 1112..1394 -> 282-tiles track\n",
      "Track generation: 1164..1459 -> 295-tiles track\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(219.3137941300869, 82.4830485963397)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cc8fdc0-502f-479e-8435-f3b80ac6ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31bfa24b-ca95-4f05-b3b7-3342550721f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1023..1282 -> 259-tiles track\n",
      "Track generation: 1227..1538 -> 311-tiles track\n",
      "Episodes 1 Score [516.29047]\n",
      "Track generation: 1258..1577 -> 319-tiles track\n",
      "Track generation: 1103..1387 -> 284-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1096..1379 -> 283-tiles track\n",
      "Episodes 2 Score [541.5094]\n",
      "Track generation: 1252..1569 -> 317-tiles track\n",
      "Track generation: 1036..1305 -> 269-tiles track\n",
      "Episodes 3 Score [412.6534]\n",
      "Track generation: 1207..1513 -> 306-tiles track\n",
      "Track generation: 955..1203 -> 248-tiles track\n",
      "Episodes 4 Score [781.97327]\n",
      "Track generation: 1105..1389 -> 284-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1332..1669 -> 337-tiles track\n",
      "Track generation: 1184..1484 -> 300-tiles track\n",
      "Episodes 5 Score [352.37674]\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print(\"Episodes {} Score {}\".format(episode, score))\n",
    "        \n",
    "#env.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9739d13-5934-4518-9226-a0b4deca9dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiproenv",
   "language": "python",
   "name": "aiproenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
